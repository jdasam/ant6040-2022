{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG7qi-1N7oCL"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/ant6040-2022/blob/main/assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2: Make Image with Gradient Ascent"
      ],
      "metadata": {
        "id": "aFYCgyJH9PEf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiHvqINX7oCN"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/jdasam/pytorch-neural-style-transfer.git\n",
        "!git clone https://github.com/gordicaleksa/pytorch-deepdream"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Deep Dream\n",
        "- Original Repository: [link](https://github.com/gordicaleksa/pytorch-deepdream)\n",
        "- Directory: `pytorch-deepdream`"
      ],
      "metadata": {
        "id": "0CxFNnS47sf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AaF9ToPD7oCO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def change_dict_to_argument_script(adict):\n",
        "  '''\n",
        "  This function converts a dictionary to a string of arguments\n",
        "  '''\n",
        "  return ' '.join(['--{} {}'.format(key, value) for key, value in adict.items()])\n",
        "\n",
        "def get_default_config_for_deepdream():\n",
        "  config = {}\n",
        "  config['input'] = 'figures.jpg'\n",
        "  config['img_width'] = 600\n",
        "  config['layers_to_use'] = 'relu4_3'\n",
        "  config['model_name'] = \"VGG16_EXPERIMENTAL\"\n",
        "  config['pretrained_weights'] = \"IMAGENET\"\n",
        "\n",
        "  config['pyramid_size'] = 4\n",
        "  config['pyramid_ratio'] = 1.8\n",
        "  config['num_gradient_ascent_iterations'] = 10\n",
        "  config['lr'] = 0.09\n",
        "\n",
        "  return config\n",
        "\n",
        "config = get_default_config_for_deepdream()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isBzLzcL7oCP"
      },
      "source": [
        "## Make your Configuration\n",
        "- `config['model_name`]: CNN model name for deep dream\n",
        "  - You can select among `VGG16_EXPERIMENTAL` or `RESNET50`\n",
        "- `config['pretrained_weights']`: The dataset name that was used for training the model for deep dream\n",
        "  - `VGG16` only support `IMAGENET`\n",
        "  - With `RESNET50`, you can also select `PLACE_365`\n",
        "- `config['input']`: File name of image in `pytorch-deepdream/data/input`. It would be used as an initial input image for Deep Dream\n",
        "- `config['img_width']`: Image pixel in width for resizing. The image would be resized before Deep Dream\n",
        "- `config['layers_to_use']`: Layers to use for Deep Dream. \n",
        "  - For VGG16, you can select among `'relu3_3', 'relu4_1', 'relu4_2', 'relu4_3', 'relu5_1', 'relu5_2', 'relu5_3', 'mp5'`\n",
        "  - For RESNET50, you can select among `'layer1', 'layer2', 'layer3', 'layer4'`\n",
        "  - Write the names of the layers separated by space:\n",
        "    - e.g. `config['layers_to_use'] = 'relu3_3 relu4_1 relu5_2`\n",
        "- `config['pyramid_size']`: Number of image pyramid iteration\n",
        "- `config['pyramid_ratio'] `: Ratio of image sizes in pyramid\n",
        "  - The width of pyramid image is decided by $w / r^{l-1}$ where $w$ is original width and $r$ is pyramid ratio and $l$ is index of pyramide level\n",
        "  - Therefore, as pyramid_ratio increases, the images will be more reduced for each pyramid level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-hY2tsO87oCP"
      },
      "outputs": [],
      "source": [
        "config = get_default_config_for_deepdream()\n",
        "\n",
        "# You can comment out the line if you don't want to change the option\n",
        "\n",
        "config['model_name'] = \"VGG16_EXPERIMENTAL\"\n",
        "config['pretrained_weights'] = \"IMAGENET\"\n",
        "\n",
        "config['input'] = 'figures.jpg' # the file has to be in pytorch-deepdream/data/input\n",
        "config['img_width'] = 600\n",
        "\n",
        "config['layers_to_use'] = 'relu4_3' \n",
        "# for VGG16, select among ['relu3_3', 'relu4_1', 'relu4_2', 'relu4_3', 'relu5_1', 'relu5_2', 'relu5_3', 'mp5']\n",
        "# for layers_to_use, write the names of the layers separated by space\n",
        "# such as 'relu3_3 relu4_1 relu4_3'\n",
        "\n",
        "config['pyramid_size'] = 4 # type=int, Number of images in an image pyramid\n",
        "config['pyramid_ratio'] = 1.8 # type=float, Ratio of image sizes in the pyramid\n",
        "config['num_gradient_ascent_iterations'] = 10 # type=int, Number of gradient ascent iterations\n",
        "config['lr'] = 0.09 # type=float, Learning rate for gradient ascent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yloGro_A7oCP"
      },
      "outputs": [],
      "source": [
        "# Make Image!\n",
        "\n",
        "arguments = change_dict_to_argument_script(config)\n",
        "!python3 pytorch-deepdream/deepdream.py $arguments\n",
        "# outputs will be saved on pytorch-deepdream/data/out-images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HweQekNt7oCQ"
      },
      "source": [
        "# 2. Neural Style Transfer\n",
        "- Original Repository: [link]()\n",
        "- Edited Repository: [link](https://github.com/jdasam/pytorch-neural-style-transfer)\n",
        "  - I have added layer selection function for `vgg16exp`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMg66Zvo7oCQ"
      },
      "outputs": [],
      "source": [
        "def change_dict_to_argument_script(adict):\n",
        "  '''\n",
        "  This function converts a dictionary to a string of arguments\n",
        "  '''\n",
        "  return ' '.join(['--{} {}'.format(key, value) for key, value in adict.items()])\n",
        "\n",
        "def get_default_config_for_nst():\n",
        "  config = {}\n",
        "  config['content_img_name'] = 'figures.jpg'\n",
        "  config['style_img_name'] = 'vg_starry_night.jpg'\n",
        "  config['height'] = 400\n",
        "\n",
        "  config['content_weight'] = 1e4\n",
        "  config['style_weight'] = 3e3\n",
        "  config['tv_weight'] = 1e-1\n",
        "\n",
        "  config['optimizer'] = 'lbfgs'\n",
        "  config['model'] = 'vgg19'\n",
        "  config['init_method'] = 'content'\n",
        "  config['saving_freq'] = -1\n",
        "\n",
        "  return config\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCHsdb8N7oCQ"
      },
      "source": [
        "## Make your Configuration\n",
        "- `config['content_img_name']`: Image file name for content image\n",
        "  - The image has to be located in `pytorch-neural-style-transfer/data/content-images/`\n",
        "  - e.g. If the image file's path is `pytorch-neural-style-transfer/data/content-images/my_content_image.jpg`, you have to enter `'my_content_image.jpg'`\n",
        "- `config['style_img_name'] `: Image file name fro style image\n",
        "  - The image has to be located in `pytorch-neural-style-transfer/data/style-images/`\n",
        "- `config['height']`: Image height in pixel that resizes\n",
        "  - The content image and style image will be resized to this specific height before NST\n",
        "\n",
        "- `config['content_weight']`: The loss weight for content\n",
        "  - If you increase this value, the optimization would focus more on reconstructing the content of content image\n",
        "  - 1e5 means $1 \\times 10^5$\n",
        "- `config['loss_weight']`: The loss weight for content\n",
        "  - If you increase this value, the optimization would focus more on reconstructing the content of content image\n",
        "  - If the loss weight is too large, it can produce `nan` loss error\n",
        "  - 3e4 means $3 \\times 10^4$\n",
        "- `config['tv_weight']`: The loss weight for total variance\n",
        "  - To make the output image smoother, we add total variance loss\n",
        "  - This calculates the difference between adjacent pixels and try to reduce their difference\n",
        "  - If you increase the value of `tv_weight`, the image would be more smoothed\n",
        "\n",
        "- `config['optimizer']`: Optimizer name for optimizing (generating) the image\n",
        "  - There are two available options that are implemented: `'lbfgs'` and `'adam'`\n",
        "  - Original paper used `'lbfgs'`\n",
        "  - People also uses `'adam'`, because it is the most popular optimizer in typical deep learning\n",
        "\n",
        "- `config['model']`: Model name code\n",
        "  - Only two available options: `'vgg16'`, and `'vgg19'`\n",
        "  - Both model shares very similar architecture, but `'vgg16'` uses 16 layers while `'vgg19'` uses 19 layers\n",
        "\n",
        "- `config['init_method']`: Initialization method\n",
        "  - Three available options: `'content'`, `'style'`, and `'random'`\n",
        "  - This select the initial image that will be optimized (transformed) to satisfy the both content and style\n",
        "  - If you want to transform style image to content image, you can select `'style'` option\n",
        "  - If you want to start from random noise, you can select `'random'`\n",
        "\n",
        "\n",
        "\n",
        "- `config['saving_freq']`: Image save frequency\n",
        "  - If the value is not -1, the program will save the image for every n-th iteration \n",
        "    - e.g. if `config['saving_freq'] = 100`, the program will save the intermediate result for every 100 iterations\n",
        "    - The number of total iteration is set to 1000 for `lbfgs`, and 3000 for `adam`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze2p19cC7oCR"
      },
      "outputs": [],
      "source": [
        "config = get_default_config_for_nst()\n",
        "\n",
        "config['content_img_name'] = 'figures.jpg'\n",
        "config['style_img_name'] = 'vg_starry_night.jpg'\n",
        "config['height'] = 400\n",
        "\n",
        "config['content_weight'] = 1e4\n",
        "config['style_weight'] = 3e3\n",
        "config['tv_weight'] = 1e-1\n",
        "\n",
        "config['optimizer'] = 'lbfgs'\n",
        "config['model'] = 'vgg16exp'\n",
        "config['init_method'] = 'content'\n",
        "config['saving_freq'] = -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g1UVCUd7oCR"
      },
      "outputs": [],
      "source": [
        "# Make Image!\n",
        "\n",
        "arguments = change_dict_to_argument_script(config)\n",
        "!python3 pytorch-neural-style-transfer/neural_style_transfer.py $arguments\n",
        "\n",
        "# The output image will be saved in pytorch-neural-style-transfer/data/output-images/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcKv0sKj7oCR"
      },
      "source": [
        "## Changing Content and Style Loss Layers\n",
        "- You can also select the layers that calculates content loss and style loss\n",
        "  - Only implemented for `config['model'] = vgg16exp`\n",
        "\n",
        "- You can select the layer by its name\n",
        "  - `config['content_layer'] = 'conv2_1'` will use the output of `conv2_1` layer for calculating content loss\n",
        "  - `config['style_layers'] = 'conv1_2 conv2_2 conv3_3'` will use the output of `conv1_2`, `conv2_2`, and `conv3_3` layers to calculate style losses\n",
        "\n",
        "- In VGG16Experimental, layers names look like this:\n",
        "  - conv1_1\n",
        "    - relu1_1 (relu of conv1_1)\n",
        "    - every conv layer has corresponding relu output\n",
        "      - e.g. the ReLU output of conv5_1 is relu5_1\n",
        "  - conv1_2\n",
        "  - conv2_1 (max_pool of relu1_2), conv2_2\n",
        "  - conv3_1 (max_pool of relu2_2), conv3_2, conv3_3\n",
        "  - conv4_1 (maxpool of relu3_3), conv4_2, conv4_3\n",
        "  - conv5_1 (maxpool of relu4_3), conv5_2, conv5_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epNwczmV7oCR"
      },
      "outputs": [],
      "source": [
        "config = get_default_config_for_nst()\n",
        "\n",
        "# It only works with vgg16exp!!!!\n",
        "config['model'] = 'vgg16exp'\n",
        "\n",
        "config['content_img_name'] = 'figures.jpg'\n",
        "config['style_img_name'] = 'vg_starry_night.jpg'\n",
        "config['height'] = 400\n",
        "\n",
        "config['content_weight'] = 1e4\n",
        "config['style_weight'] = 3e3\n",
        "config['tv_weight'] = 1e-1\n",
        "\n",
        "config['optimizer'] = 'lbfgs'\n",
        "config['init_method'] = 'content'\n",
        "config['saving_freq'] = -1\n",
        "\n",
        "config['content_layer'] = 'conv1_1'\n",
        "config['style_layers'] = 'conv2_1 conv2_2 conv3_1'\n",
        "\n",
        "\n",
        "# Make Image\n",
        "arguments = change_dict_to_argument_script(config)\n",
        "!python3 pytorch-neural-style-transfer/neural_style_transfer.py $arguments\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}